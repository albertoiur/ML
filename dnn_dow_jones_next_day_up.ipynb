{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "from keras import Sequential\n",
    "\n",
    "# Import TensorFlow and TensorFlow Datasets\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Helper libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "\n",
    "# Improve progress bar display\n",
    "#import tqdm\n",
    "#import tqdm.auto\n",
    "#tqdm.tqdm = tqdm.auto.tqdm\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "print(tf.__version__)\n",
    "#print(keras.__version__)\n",
    "\n",
    "# This will go away in the future.\n",
    "# If this gives an error, you might be running TensorFlow 2 or above\n",
    "# If so, the just comment out this line and run this cell again\n",
    "#tf.enable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock = pd.read_csv('dow_jones_up_nextday.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UP                           1.000000\n",
       "RSI                          0.332973\n",
       "StochaticOscillator          0.309453\n",
       "William%R                    0.309453\n",
       "CrossPrice                   0.254527\n",
       "StochaticOscillatorSignal    0.237688\n",
       "MoneyFlowIndex               0.236465\n",
       "UltimateOscillator           0.215754\n",
       "bb_high_indicator            0.168448\n",
       "CrossMM                      0.117072\n",
       "TrueStrengthIndex            0.037346\n",
       "Low                          0.031404\n",
       "Open                         0.030952\n",
       "Close                        0.030755\n",
       "High                         0.030523\n",
       "Adj Close                    0.029494\n",
       "AwesomeOscillator            0.026123\n",
       "MM4                          0.025677\n",
       "MM9                          0.023190\n",
       "MM18                         0.022231\n",
       "Volume                       0.006663\n",
       "Unnamed: 0                   0.001787\n",
       "Change                       0.000101\n",
       "bb_low_indicator            -0.141648\n",
       "Name: UP, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = stock.corr()\n",
    "corr_matrix[\"UP\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split train/sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Criar tabela com 'features', e com respectiva label (UP)\n",
    "y = stock['UP']\n",
    "#X = output[['RSI','Volume','MoneyFlowIndex','bb_high_indicator','CrossMM']]\n",
    "X = stock[['Volume','High','Low','RSI','CrossMM','CrossPrice','bb_high_indicator','MoneyFlowIndex','Open','MM4','MM9','MM18','StochaticOscillator', 'William%R', 'UltimateOscillator', 'StochaticOscillatorSignal' ]]\n",
    "\n",
    "#X = output.drop(['UP'],axis=1)\n",
    "#Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67203, 16)\n",
      "(22401, 16)\n",
      "(67203,)\n",
      "(22401,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_sca = sc.fit_transform(X_train)\n",
    "X_test_sca = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10384951,  0.24958081,  0.25817738, ...,  1.39254967,\n",
       "         0.50064449,  1.12285875],\n",
       "       [ 2.81028078, -0.86461125, -0.86293014, ..., -0.24554092,\n",
       "         0.17460128, -0.15334186],\n",
       "       [ 0.11720184,  0.54613202,  0.53922898, ...,  0.66766687,\n",
       "         0.42792635,  0.1527303 ],\n",
       "       ..., \n",
       "       [ 1.07235445, -0.17580815, -0.17686812, ...,  0.7375069 ,\n",
       "         2.49210841,  1.20123264],\n",
       "       [-0.00681925, -0.88501038, -0.88375347, ..., -1.72792002,\n",
       "        -1.73165872, -1.50926052],\n",
       "       [-0.57031737, -0.85197804, -0.85004789, ...,  0.45045746,\n",
       "         0.12945599,  0.64462199]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelo = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, input_shape=[16],activation=tf.nn.relu), \n",
    "    tf.keras.layers.Dense(50,activation=tf.nn.relu), \n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.6124 - acc: 0.6587     \n",
      "Epoch 2/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5970 - acc: 0.6732     \n",
      "Epoch 3/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5950 - acc: 0.6745     \n",
      "Epoch 4/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5936 - acc: 0.6751     - ETA: 1s - loss: 0.587\n",
      "Epoch 5/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5926 - acc: 0.6774     \n",
      "Epoch 6/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5913 - acc: 0.6776     \n",
      "Epoch 7/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5901 - acc: 0.6795     \n",
      "Epoch 8/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5886 - acc: 0.6813     \n",
      "Epoch 9/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5873 - acc: 0.6821     \n",
      "Epoch 10/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5862 - acc: 0.6838     \n",
      "Epoch 11/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5851 - acc: 0.6838     \n",
      "Epoch 12/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5849 - acc: 0.6858     - ETA: 1s - loss: 0.5878\n",
      "Epoch 13/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5834 - acc: 0.6859     \n",
      "Epoch 14/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5820 - acc: 0.6865     \n",
      "Epoch 15/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5815 - acc: 0.6864     \n",
      "Epoch 16/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5804 - acc: 0.6878     \n",
      "Epoch 17/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5801 - acc: 0.6877     \n",
      "Epoch 18/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5781 - acc: 0.6899     \n",
      "Epoch 19/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5774 - acc: 0.6896     \n",
      "Epoch 20/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5771 - acc: 0.6909     \n",
      "Epoch 21/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5761 - acc: 0.6915     \n",
      "Epoch 22/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5753 - acc: 0.6922     \n",
      "Epoch 23/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5745 - acc: 0.6938     \n",
      "Epoch 24/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5735 - acc: 0.6933     \n",
      "Epoch 25/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5731 - acc: 0.6943     \n",
      "Epoch 26/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5720 - acc: 0.6955     \n",
      "Epoch 27/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5726 - acc: 0.6955     \n",
      "Epoch 28/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5709 - acc: 0.6972     \n",
      "Epoch 29/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5699 - acc: 0.6980     \n",
      "Epoch 30/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5702 - acc: 0.6970     \n",
      "Epoch 31/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5692 - acc: 0.6991     \n",
      "Epoch 32/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5686 - acc: 0.6990     \n",
      "Epoch 33/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5672 - acc: 0.7002     \n",
      "Epoch 34/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5675 - acc: 0.7001     \n",
      "Epoch 35/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5665 - acc: 0.7014     \n",
      "Epoch 36/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5658 - acc: 0.7006     \n",
      "Epoch 37/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5657 - acc: 0.7005     \n",
      "Epoch 38/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5642 - acc: 0.7029     \n",
      "Epoch 39/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5631 - acc: 0.7045     \n",
      "Epoch 40/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5642 - acc: 0.7027     \n",
      "Epoch 41/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5629 - acc: 0.7047     \n",
      "Epoch 42/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5614 - acc: 0.7061     \n",
      "Epoch 43/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5607 - acc: 0.7061     \n",
      "Epoch 44/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5600 - acc: 0.7080     \n",
      "Epoch 45/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5599 - acc: 0.7066     \n",
      "Epoch 46/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5595 - acc: 0.7080     \n",
      "Epoch 47/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5587 - acc: 0.7078     \n",
      "Epoch 48/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5578 - acc: 0.7088     \n",
      "Epoch 49/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5573 - acc: 0.7098     \n",
      "Epoch 50/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5560 - acc: 0.7116     \n",
      "Epoch 51/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5553 - acc: 0.7129     \n",
      "Epoch 52/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5551 - acc: 0.7114     \n",
      "Epoch 53/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5529 - acc: 0.7147     \n",
      "Epoch 54/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5538 - acc: 0.7122     \n",
      "Epoch 55/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5536 - acc: 0.7134     \n",
      "Epoch 56/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5523 - acc: 0.7140     \n",
      "Epoch 57/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5510 - acc: 0.7153     \n",
      "Epoch 58/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5495 - acc: 0.7171     \n",
      "Epoch 59/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5499 - acc: 0.7155     \n",
      "Epoch 60/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5482 - acc: 0.7178     \n",
      "Epoch 61/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5484 - acc: 0.7167     \n",
      "Epoch 62/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5480 - acc: 0.7166     \n",
      "Epoch 63/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5461 - acc: 0.7201     \n",
      "Epoch 64/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5455 - acc: 0.7214     \n",
      "Epoch 65/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5449 - acc: 0.7210     \n",
      "Epoch 66/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5447 - acc: 0.7212     \n",
      "Epoch 67/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5443 - acc: 0.7208     \n",
      "Epoch 68/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5430 - acc: 0.7233     \n",
      "Epoch 69/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5424 - acc: 0.7239     \n",
      "Epoch 70/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5424 - acc: 0.7232     \n",
      "Epoch 71/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5442 - acc: 0.7223     \n",
      "Epoch 72/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5403 - acc: 0.7253     \n",
      "Epoch 73/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5423 - acc: 0.7251     \n",
      "Epoch 74/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5386 - acc: 0.7267     \n",
      "Epoch 75/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5378 - acc: 0.7255     \n",
      "Epoch 76/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5410 - acc: 0.7245     \n",
      "Epoch 77/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5386 - acc: 0.7255     \n",
      "Epoch 78/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5367 - acc: 0.7296     \n",
      "Epoch 79/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5359 - acc: 0.7291     \n",
      "Epoch 80/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5379 - acc: 0.7259     \n",
      "Epoch 81/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5358 - acc: 0.7287     \n",
      "Epoch 82/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5372 - acc: 0.7273     \n",
      "Epoch 83/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5373 - acc: 0.7271     \n",
      "Epoch 84/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5323 - acc: 0.7323     \n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67203/67203 [==============================] - 0s - loss: 0.5326 - acc: 0.7319     \n",
      "Epoch 86/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5334 - acc: 0.7311     \n",
      "Epoch 87/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5321 - acc: 0.7305     \n",
      "Epoch 88/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5327 - acc: 0.7309     \n",
      "Epoch 89/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5317 - acc: 0.7321     \n",
      "Epoch 90/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5324 - acc: 0.7327     \n",
      "Epoch 91/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5313 - acc: 0.7328     \n",
      "Epoch 92/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5309 - acc: 0.7330     \n",
      "Epoch 93/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5306 - acc: 0.7320     \n",
      "Epoch 94/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5305 - acc: 0.7333     \n",
      "Epoch 95/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5282 - acc: 0.7349     \n",
      "Epoch 96/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5282 - acc: 0.7351     \n",
      "Epoch 97/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5267 - acc: 0.7375     \n",
      "Epoch 98/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5299 - acc: 0.7339     \n",
      "Epoch 99/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5287 - acc: 0.7348     \n",
      "Epoch 100/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5270 - acc: 0.7360     \n",
      "Epoch 101/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5260 - acc: 0.7370     \n",
      "Epoch 102/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5271 - acc: 0.7357     \n",
      "Epoch 103/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5244 - acc: 0.7396     \n",
      "Epoch 104/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5254 - acc: 0.7385     \n",
      "Epoch 105/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5272 - acc: 0.7360     \n",
      "Epoch 106/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5229 - acc: 0.7396     \n",
      "Epoch 107/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5242 - acc: 0.7375     \n",
      "Epoch 108/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5226 - acc: 0.7407     \n",
      "Epoch 109/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5259 - acc: 0.7367     \n",
      "Epoch 110/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5223 - acc: 0.7395     \n",
      "Epoch 111/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5234 - acc: 0.7398     \n",
      "Epoch 112/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5220 - acc: 0.7400     \n",
      "Epoch 113/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5222 - acc: 0.7403     \n",
      "Epoch 114/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5199 - acc: 0.7417     \n",
      "Epoch 115/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5206 - acc: 0.7409     \n",
      "Epoch 116/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5192 - acc: 0.7431     \n",
      "Epoch 117/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5181 - acc: 0.7430     \n",
      "Epoch 118/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5195 - acc: 0.7422     \n",
      "Epoch 119/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5197 - acc: 0.7421     \n",
      "Epoch 120/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5180 - acc: 0.7436     \n",
      "Epoch 121/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5186 - acc: 0.7425     \n",
      "Epoch 122/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5197 - acc: 0.7402     \n",
      "Epoch 123/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5178 - acc: 0.7442     \n",
      "Epoch 124/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5158 - acc: 0.7449     \n",
      "Epoch 125/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5191 - acc: 0.7424     \n",
      "Epoch 126/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5160 - acc: 0.7457     \n",
      "Epoch 127/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5147 - acc: 0.7453     \n",
      "Epoch 128/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5158 - acc: 0.7451     \n",
      "Epoch 129/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5167 - acc: 0.7440     \n",
      "Epoch 130/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5154 - acc: 0.7459     \n",
      "Epoch 131/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5145 - acc: 0.7454     \n",
      "Epoch 132/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5135 - acc: 0.7463     \n",
      "Epoch 133/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5143 - acc: 0.7477     \n",
      "Epoch 134/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5183 - acc: 0.7437     \n",
      "Epoch 135/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5157 - acc: 0.7438     \n",
      "Epoch 136/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5120 - acc: 0.7479     \n",
      "Epoch 137/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5156 - acc: 0.7439     \n",
      "Epoch 138/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5132 - acc: 0.7464     \n",
      "Epoch 139/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5123 - acc: 0.7476     \n",
      "Epoch 140/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5128 - acc: 0.7473     \n",
      "Epoch 141/150\n",
      "67203/67203 [==============================] - 0s - loss: 0.5141 - acc: 0.7477     \n",
      "Epoch 142/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5113 - acc: 0.7493     \n",
      "Epoch 143/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5105 - acc: 0.7489     \n",
      "Epoch 144/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5132 - acc: 0.7467     \n",
      "Epoch 145/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5107 - acc: 0.7498     \n",
      "Epoch 146/150\n",
      "67203/67203 [==============================] - ETA: 0s - loss: 0.5118 - acc: 0.746 - 0s - loss: 0.5128 - acc: 0.7461     \n",
      "Epoch 147/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5147 - acc: 0.7447     \n",
      "Epoch 148/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5097 - acc: 0.7499     \n",
      "Epoch 149/150\n",
      "67203/67203 [==============================] - 1s - loss: 0.5095 - acc: 0.7493     \n",
      "Epoch 150/150\n",
      "67203/67203 [==============================] - ETA: 0s - loss: 0.5097 - acc: 0.749 - 1s - loss: 0.5093 - acc: 0.7495     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x24a79f0d400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(X_train_sca, y_train, batch_size = 500, epochs = 150, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73264586402392751"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = modelo.predict(X_test_sca)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8387 3024]\n",
      " [2965 8025]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD1CAYAAABZc+A8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24a00f97278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "pl.matshow(cm)\n",
    "pl.title('Confusion matrix of the classifier')\n",
    "pl.colorbar()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance de acertos:  0.72631007331\n",
      "True Positive Rate:  0.730209281165\n",
      "F1 Score:  0.728254458006\n"
     ]
    }
   ],
   "source": [
    "# F1_score - (precision and recall: dados train)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print('Performance de acertos: ',precision_score(y_test, y_pred))\n",
    "print('True Positive Rate: ',recall_score(y_test,y_pred))\n",
    "print('F1 Score: ',f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47990    1.0\n",
      "15343    0.0\n",
      "32013    0.0\n",
      "40143    1.0\n",
      "10706    1.0\n",
      "13022    1.0\n",
      "80781    0.0\n",
      "33209    1.0\n",
      "62869    0.0\n",
      "9313     0.0\n",
      "Name: UP, dtype: float64 [1 0 0 1 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[12010:12020],y_pred[12010:12020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor Binário (0) ADS.DE --> [[ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.1  0.9]\n",
      " [ 1.   0. ]\n",
      " [ 0.9  0.1]]\n",
      "Valor Binário (0) ALV.DE --> [[ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.6  0.4]\n",
      " [ 0.9  0.1]\n",
      " [ 0.   1. ]]\n",
      "Valor Binário (0) BAS.DE --> [[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Valor Binário (0) BAYN.DE --> [[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "Valor Binário (0) BEI.DE --> [[ 0.9  0.1]\n",
      " [ 0.4  0.6]\n",
      " [ 0.3  0.7]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]]\n",
      "Valor Binário (0) BMW.DE --> [[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Valor Binário (0) CBK.DE --> [[ 0.   1. ]\n",
      " [ 0.8  0.2]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]]\n",
      "Valor Binário (0) CON.DE --> [[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]]\n",
      "Valor Binário (0) DAI.DE --> [[ 0.2  0.8]\n",
      " [ 0.   1. ]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]]\n",
      "Valor Binário (0) DB1.DE --> [[ 0.6  0.4]\n",
      " [ 0.5  0.5]\n",
      " [ 0.1  0.9]\n",
      " [ 0.8  0.2]\n",
      " [ 1.   0. ]]\n",
      "Valor Binário (0) DBK.DE --> [[ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Valor Binário (0) DPW.DE --> [[ 0.3  0.7]\n",
      " [ 0.   1. ]\n",
      " [ 0.9  0.1]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]]\n",
      "Valor Binário (0) DTE.DE --> [[ 1.   0. ]\n",
      " [ 0.5  0.5]\n",
      " [ 0.4  0.6]\n",
      " [ 1.   0. ]\n",
      " [ 0.   1. ]]\n",
      "Valor Binário (0) EOAN.DE --> [[ 1.   0. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.1  0.9]\n",
      " [ 0.7  0.3]\n",
      " [ 0.   1. ]]\n",
      "Valor Binário (0) FME.DE --> [[ 0.   1. ]\n",
      " [ 1.   0. ]\n",
      " [ 0.5  0.5]\n",
      " [ 0.   1. ]\n",
      " [ 0.5  0.5]]\n",
      "Valor Binário (0) FRE.DE --> [[ 0.9  0.1]\n",
      " [ 1.   0. ]\n",
      " [ 0.1  0.9]\n",
      " [ 0.   1. ]\n",
      " [ 0.8  0.2]]\n",
      "Valor Binário (0) HEI.DE --> [[ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 1.   0. ]\n",
      " [ 0.6  0.4]\n",
      " [ 0.9  0.1]]\n",
      "Valor Binário (0) HEN3.DE --> [[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "Valor Binário (0) IFX.DE --> [[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Valor Binário (0) LHA.DE --> [[ 1.   0. ]\n",
      " [ 0.3  0.7]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]]\n",
      "Valor Binário (0) LIN.DE --> [[ 0.9  0.1]\n",
      " [ 0.2  0.8]\n",
      " [ 0.9  0.1]\n",
      " [ 0.9  0.1]\n",
      " [ 1.   0. ]]\n",
      "Valor Binário (0) MRK.DE --> [[ 0.2  0.8]\n",
      " [ 0.7  0.3]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]]\n",
      "Valor Binário (0) MUV2.DE --> [[ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 1.   0. ]\n",
      " [ 0.1  0.9]]\n",
      "Valor Binário (0) PSM.DE --> [[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Valor Binário (0) RWE.DE --> [[ 1.   0. ]\n",
      " [ 0.5  0.5]\n",
      " [ 0.8  0.2]\n",
      " [ 0.6  0.4]\n",
      " [ 0.5  0.5]]\n",
      "Valor Binário (0) SAP.DE --> [[ 0.9  0.1]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]]\n",
      "Valor Binário (0) SIE.DE --> [[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "Valor Binário (0) TKA.DE --> [[ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 1.   0. ]\n",
      " [ 1.   0. ]\n",
      " [ 0.8  0.2]]\n",
      "Valor Binário (0) VNA.DE --> [[ 0.5  0.5]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]\n",
      " [ 0.   1. ]]\n",
      "Valor Binário (0) VOW3.DE --> [[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from stockstats import StockDataFrame as Sdf\n",
    "from ta import *\n",
    "%matplotlib inline\n",
    "\n",
    "nome_ficheiro = 'lista_dax.txt'\n",
    "#nome_ficheiro = 'lista_dowj.csv'\n",
    "\n",
    "try:\n",
    "        fhand = open(nome_ficheiro)\n",
    "\n",
    "except:\n",
    "        print ('Nao e possivel abrir o ficheiro: ', fhand)\n",
    "\n",
    "\n",
    "lista_quotes = []\n",
    "\n",
    "#Cria lista com os ticket do SP500\n",
    "for f in fhand:\n",
    "    linha = f.strip().split(',')\n",
    "    ticker = linha[0]\n",
    "    lista_quotes.append(ticker)\n",
    "\n",
    "\n",
    "for quote in lista_quotes:\n",
    "    try:\n",
    "        stock = pd.read_csv('dados_actuais_'+quote+'_280419.csv')\n",
    "        #stock = pd.read_csv('dados_actuais_dowj_'+quote+'_260419.csv')\n",
    "        output = stock\n",
    "    except:\n",
    "        continue    \n",
    "    \n",
    "    # Utilizando a livaria 'ta'\n",
    "    # Add bollinger band high indicator filling NaN values\n",
    "    output['bb_high_indicator'] = bollinger_hband_indicator(output[\"Close\"], n=20, ndev=2, fillna=True)\n",
    "    # Add bollinger band low indicator filling NaN values\n",
    "    output['bb_low_indicator'] = bollinger_lband_indicator(output[\"Close\"], n=20, ndev=2, fillna=True)\n",
    "    # Adicionar Money Flow Index\n",
    "    output['MoneyFlowIndex'] = money_flow_index(output[\"High\"],output[\"Low\"],output[\"Close\"],output[\"Volume\"],n=14, fillna=True)\n",
    "    # Adicionar AwesomeOscillator\n",
    "    output['AwesomeOscillator'] = ao(output[\"High\"],output[\"Low\"], s=5, l=34, fillna=True)\n",
    "    # Adicionar Stochatic Oscillator\n",
    "    output['StochaticOscillator'] = stoch(output[\"High\"],output[\"Low\"],output[\"Close\"], n=14, fillna=True)\n",
    "    # Adicionar Stochatic Oscillator Signal\n",
    "    output['StochaticOscillatorSignal'] = stoch_signal(output[\"High\"],output[\"Low\"],output[\"Close\"], n=14, d_n=3, fillna=True)\n",
    "    # Adicionar True Strength Index\n",
    "    output['TrueStrengthIndex'] = tsi(output[\"Close\"], r=25, s=13, fillna=True)\n",
    "    # Adicionar Ultimate Oscillator\n",
    "    output['UltimateOscillator'] = uo(output[\"High\"],output[\"Low\"],output[\"Close\"], s=7, m=14, l=28, ws=4.0, wm=2.0, wl=1.0, fillna=True)\n",
    "    # Adicionar William % R\n",
    "    output['William%R'] = wr(output[\"High\"],output[\"Low\"],output[\"Close\"], lbp=14, fillna=True)\n",
    "    # Adicionar RSI\n",
    "    output['RSI'] = rsi(output[\"Close\"], n=14, fillna=True)\n",
    "    \n",
    "    # Adicionar features (MM4,MM9,MM18) e uma label (1=Subiu, 0=Desceu)\n",
    "\n",
    "    output['Change'] = output['Close'].pct_change()\n",
    "    output['UP'] = np.where(output['Change'] >= 0.0,1,0)\n",
    "    output['MM4'] = output['Close'].rolling(window=4).mean()\n",
    "    output['MM9'] = output['Close'].rolling(window=9).mean()\n",
    "    output['MM18'] = output['Close'].rolling(window=18).mean()\n",
    "    output['CrossMM'] = np.where(output['MM4'] > output['MM18'],1.0,0.0)\n",
    "    output['CrossPrice'] = np.where(output['Open'] > output['MM18'],1.0,0.0)\n",
    "    \n",
    "    # Preencher os dados em falta\n",
    "\n",
    "    media4 = output['MM4'].mean()\n",
    "    media9 = output['MM9'].mean()\n",
    "    media18 = output['MM18'].mean()\n",
    "    output['MM4'].fillna(media4, inplace=True)\n",
    "    output['MM9'].fillna(media9, inplace=True)\n",
    "    output['MM18'].fillna(media18, inplace=True)\n",
    "    output['Change'].fillna(0, inplace=True)    \n",
    "    \n",
    "    \n",
    "    # Criar tabela com 'features', e com respectiva label (UP)\n",
    "    y = output['UP']\n",
    "    X = output[['Volume','High','Low','RSI','CrossMM','CrossPrice','bb_high_indicator','MoneyFlowIndex','Open','MM4','MM9','MM18','StochaticOscillator', 'William%R', 'UltimateOscillator', 'StochaticOscillatorSignal' ]]\n",
    "\n",
    "    #Split \n",
    "    \n",
    "    tamanho_t = len(X)\n",
    "    terco = int(tamanho_t/3)\n",
    "    tr = tamanho_t - terco\n",
    "    \n",
    "    \n",
    "    X_train = X.head(tr)\n",
    "    X_test  = X.tail(terco)\n",
    "    y_train = y.head(tr)\n",
    "    y_test = y.tail(terco)\n",
    "    \n",
    "    #Scaling\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train_sca = sc.fit_transform(X_train)\n",
    "    X_test_sca = sc.transform(X_test)\n",
    "    \n",
    "        \n",
    "    y_pred = modelo.predict(X_test_sca).astype(np.double).round(decimals=1)[-5:]\n",
    "    print('Valor Binário (0)', quote, '-->', y_pred)\n",
    "    \n",
    "    \n",
    "    #print('Valor Binário (0)', quote, '-->', obj.predict(X_test_sca)[-5:])    \n",
    "    #print('Valor Probabilistico', quote, '-->', (obj.predict_proba(X_test_sca)[:,1]).astype(np.double).round(decimals=3)[-5:])\n",
    "    #print('----------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
