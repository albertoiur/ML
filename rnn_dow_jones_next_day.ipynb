{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ta import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pylab as pl\n",
    "\n",
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.8-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Carregar dados\n",
    "stock = pd.read_csv('dow_jones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.721354</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.018480</td>\n",
       "      <td>3451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.721354</td>\n",
       "      <td>0.018959</td>\n",
       "      <td>3960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-04</td>\n",
       "      <td>0.721354</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.019165</td>\n",
       "      <td>1694400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-07</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.726563</td>\n",
       "      <td>0.019096</td>\n",
       "      <td>4396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-08</td>\n",
       "      <td>0.726563</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.726563</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.019233</td>\n",
       "      <td>3244800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close   Volume\n",
       "0  1980-01-02  0.718750  0.721354  0.703125  0.703125   0.018480  3451200\n",
       "1  1980-01-03  0.703125  0.723958  0.697917  0.721354   0.018959  3960000\n",
       "2  1980-01-04  0.721354  0.729167  0.718750  0.729167   0.019165  1694400\n",
       "3  1980-01-07  0.729167  0.731771  0.723958  0.726563   0.019096  4396800\n",
       "4  1980-01-08  0.726563  0.734375  0.726563  0.731771   0.019233  3244800"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utilizando a livaria 'ta'\n",
    "# Add bollinger band high indicator filling NaN values\n",
    "stock['bb_high_indicator'] = bollinger_hband_indicator(stock[\"Close\"], n=20, ndev=2, fillna=True)\n",
    "# Add bollinger band low indicator filling NaN values\n",
    "stock['bb_low_indicator'] = bollinger_lband_indicator(stock[\"Close\"], n=20, ndev=2, fillna=True)\n",
    "# Adicionar Money Flow Index\n",
    "stock['MoneyFlowIndex'] = money_flow_index(stock[\"High\"],stock[\"Low\"],stock[\"Close\"],stock[\"Volume\"],n=14, fillna=True)\n",
    "# Adicionar AwesomeOscillator\n",
    "stock['AwesomeOscillator'] = ao(stock[\"High\"],stock[\"Low\"], s=5, l=34, fillna=True)\n",
    "# Adicionar Stochatic Oscillator\n",
    "stock['StochaticOscillator'] = stoch(stock[\"High\"],stock[\"Low\"],stock[\"Close\"], n=14, fillna=True)\n",
    "# Adicionar Stochatic Oscillator Signal\n",
    "stock['StochaticOscillatorSignal'] = stoch_signal(stock[\"High\"],stock[\"Low\"],stock[\"Close\"], n=14, d_n=3, fillna=True)\n",
    "# Adicionar True Strength Index\n",
    "stock['TrueStrengthIndex'] = tsi(stock[\"Close\"], r=25, s=13, fillna=True)\n",
    "# Adicionar Ultimate Oscillator\n",
    "stock['UltimateOscillator'] = uo(stock[\"High\"],stock[\"Low\"],stock[\"Close\"], s=7, m=14, l=28, ws=4.0, wm=2.0, wl=1.0, fillna=True)\n",
    "# Adicionar William % R\n",
    "stock['William%R'] = wr(stock[\"High\"],stock[\"Low\"],stock[\"Close\"], lbp=14, fillna=True)\n",
    "# Adicionar RSI\n",
    "stock['RSI'] = rsi(stock[\"Close\"], n=14, fillna=True)\n",
    "\n",
    "# Adicionar features (MM4,MM9,MM18) e uma label (1=Subiu, 0=Desceu)\n",
    "\n",
    "stock['Change'] = stock['High'].pct_change()\n",
    "stock['MM4'] = stock['Close'].rolling(window=4).mean()\n",
    "stock['MM9'] = stock['Close'].rolling(window=9).mean()\n",
    "stock['MM18'] = stock['Close'].rolling(window=18).mean()\n",
    "stock['CrossMM'] = np.where(stock['MM4'] > stock['MM18'],1.0,0.0)\n",
    "stock['CrossPrice'] = np.where(stock['Open'] > stock['MM18'],1.0,0.0)\n",
    "    \n",
    "# Preencher os dados em falta\n",
    "stock['UP'] = np.where(stock['Change'] > 0.00, 1, 0)\n",
    "media4 = stock['MM4'].mean()\n",
    "media9 = stock['MM9'].mean()\n",
    "media18 = stock['MM18'].mean()\n",
    "stock['MM4'].fillna(media4, inplace=True)\n",
    "stock['MM9'].fillna(media9, inplace=True)\n",
    "stock['MM18'].fillna(media18, inplace=True)\n",
    "stock['Change'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>bb_high_indicator</th>\n",
       "      <th>bb_low_indicator</th>\n",
       "      <th>MoneyFlowIndex</th>\n",
       "      <th>...</th>\n",
       "      <th>UltimateOscillator</th>\n",
       "      <th>William%R</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Change</th>\n",
       "      <th>MM4</th>\n",
       "      <th>MM9</th>\n",
       "      <th>MM18</th>\n",
       "      <th>CrossMM</th>\n",
       "      <th>CrossPrice</th>\n",
       "      <th>UP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.721354</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.018480</td>\n",
       "      <td>3451200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.396759</td>\n",
       "      <td>36.397601</td>\n",
       "      <td>36.399115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.721354</td>\n",
       "      <td>0.018959</td>\n",
       "      <td>3960000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>36.396759</td>\n",
       "      <td>36.397601</td>\n",
       "      <td>36.399115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-04</td>\n",
       "      <td>0.721354</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.019165</td>\n",
       "      <td>1694400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>36.396759</td>\n",
       "      <td>36.397601</td>\n",
       "      <td>36.399115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-07</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.726563</td>\n",
       "      <td>0.019096</td>\n",
       "      <td>4396800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>88.711278</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.720052</td>\n",
       "      <td>36.397601</td>\n",
       "      <td>36.399115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-08</td>\n",
       "      <td>0.726563</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.726563</td>\n",
       "      <td>0.731771</td>\n",
       "      <td>0.019233</td>\n",
       "      <td>3244800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>91.044315</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.727214</td>\n",
       "      <td>36.397601</td>\n",
       "      <td>36.399115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close  Adj Close   Volume  \\\n",
       "0  1980-01-02  0.718750  0.721354  0.703125  0.703125   0.018480  3451200   \n",
       "1  1980-01-03  0.703125  0.723958  0.697917  0.721354   0.018959  3960000   \n",
       "2  1980-01-04  0.721354  0.729167  0.718750  0.729167   0.019165  1694400   \n",
       "3  1980-01-07  0.729167  0.731771  0.723958  0.726563   0.019096  4396800   \n",
       "4  1980-01-08  0.726563  0.734375  0.726563  0.731771   0.019233  3244800   \n",
       "\n",
       "   bb_high_indicator  bb_low_indicator  MoneyFlowIndex ...   \\\n",
       "0                0.0               0.0            50.0 ...    \n",
       "1                0.0               0.0            50.0 ...    \n",
       "2                0.0               0.0            50.0 ...    \n",
       "3                0.0               0.0            50.0 ...    \n",
       "4                0.0               0.0            50.0 ...    \n",
       "\n",
       "   UltimateOscillator  William%R         RSI    Change        MM4        MM9  \\\n",
       "0                50.0      -50.0   50.000000  0.000000  36.396759  36.397601   \n",
       "1                50.0      -50.0  100.000000  0.003610  36.396759  36.397601   \n",
       "2                50.0      -50.0  100.000000  0.007195  36.396759  36.397601   \n",
       "3                50.0      -50.0   88.711278  0.003571   0.720052  36.397601   \n",
       "4                50.0      -50.0   91.044315  0.003558   0.727214  36.397601   \n",
       "\n",
       "        MM18  CrossMM  CrossPrice   UP  \n",
       "0  36.399115      0.0         0.0  1.0  \n",
       "1  36.399115      0.0         0.0  0.0  \n",
       "2  36.399115      0.0         0.0  1.0  \n",
       "3  36.399115      0.0         0.0  1.0  \n",
       "4  36.399115      0.0         0.0  1.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.UP = stock.UP.shift(1)\n",
    "stock['UP'].fillna(1,inplace=True)\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
       "       'bb_high_indicator', 'bb_low_indicator', 'MoneyFlowIndex',\n",
       "       'AwesomeOscillator', 'StochaticOscillator', 'StochaticOscillatorSignal',\n",
       "       'TrueStrengthIndex', 'UltimateOscillator', 'William%R', 'RSI', 'Change',\n",
       "       'MM4', 'MM9', 'MM18', 'CrossMM', 'CrossPrice', 'UP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UP                           1.000000\n",
       "RSI                          0.339836\n",
       "William%R                    0.317717\n",
       "StochaticOscillator          0.317717\n",
       "StochaticOscillatorSignal    0.303840\n",
       "CrossPrice                   0.273471\n",
       "UltimateOscillator           0.233278\n",
       "MoneyFlowIndex               0.187367\n",
       "bb_high_indicator            0.170578\n",
       "CrossMM                      0.155692\n",
       "Change                       0.065955\n",
       "TrueStrengthIndex            0.046477\n",
       "Low                          0.039495\n",
       "Open                         0.039046\n",
       "Close                        0.038991\n",
       "High                         0.038692\n",
       "Adj Close                    0.037722\n",
       "AwesomeOscillator            0.037302\n",
       "MM4                          0.034319\n",
       "MM9                          0.030899\n",
       "MM18                         0.029501\n",
       "Volume                       0.012527\n",
       "bb_low_indicator            -0.138687\n",
       "Name: UP, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = stock.corr()\n",
    "corr_matrix[\"UP\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input dados\n",
    "stock_new = stock[['Volume','High','Low','RSI','CrossMM','CrossPrice','bb_high_indicator','MoneyFlowIndex','Open','MM4','MM9','MM18','StochaticOscillator', 'William%R', 'UltimateOscillator', 'StochaticOscillatorSignal' ]]\n",
    "#target\n",
    "target_name = stock['UP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Shape: (89604, 16)\n"
     ]
    }
   ],
   "source": [
    "#NumPy Arrays\n",
    "#We now convert the Pandas data-frames to NumPy arrays that can be input to the neural network.\n",
    "#These are the input-signals:\n",
    "\n",
    "x_data = stock_new.values[:]\n",
    "print(type(x_data))\n",
    "print(\"Shape:\", x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Shape: (89604,)\n"
     ]
    }
   ],
   "source": [
    "#These are the output-signals (or target-signals):\n",
    "\n",
    "y_data = target_name.values[:]\n",
    "print(type(y_data))\n",
    "print(\"Shape:\", y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89604"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the number of observations (aka. data-points or samples) in the data-set:\n",
    "num_data = len(x_data)\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the fraction of the data-set that will be used for the training-set:\n",
    "train_split = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80643"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the number of observations in the training-set:\n",
    "num_train = int(train_split * num_data)\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8961"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the number of observations in the test-set:\n",
    "num_test = num_data - num_train\n",
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89604"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the input-signals for the training- and test-sets:\n",
    "x_train = x_data[0:num_train]\n",
    "x_test = x_data[num_train:]\n",
    "len(x_train) + len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89604"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the output-signals for the training- and test-sets:\n",
    "y_train = y_data[0:num_train]\n",
    "y_test = y_data[num_train:]\n",
    "len(y_train) + len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the number of input-signals:\n",
    "num_x_signals = x_data.shape[1]\n",
    "num_x_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the number of output-signals:\n",
    "num_y_signals = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -100.0\n",
      "Max: 1031788800.0\n"
     ]
    }
   ],
   "source": [
    "#Scaled Data\n",
    "#The data-set contains a wide range of values:\n",
    "\n",
    "print(\"Min:\", np.min(x_train))\n",
    "print(\"Max:\", np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The neural network works best on values roughly between -1 and 1, so we need to scale the data before it is being input \n",
    "#to the neural network. We can use scikit-learn for this.\n",
    "#We first create a scaler-object for the input-signals\n",
    "\n",
    "x_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We then detect the range of values from the training-data and scale the training-data.\n",
    "x_train_scaled = x_scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0\n",
      "Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Apart from a small rounding-error, the data has been scaled to be between 0 and 1.\n",
    "print(\"Min:\", np.min(x_train_scaled))\n",
    "print(\"Max:\", np.max(x_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We use the same scaler-object for the input-signals in the test-set.\n",
    "x_test_scaled = x_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80643, 16)\n",
      "(80643, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_scaled.shape)\n",
    "print(y_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instead of training the Recurrent Neural Network on the complete sequences of almost 8000 observations, we will use the \n",
    "#following function to create a batch of shorter sub-sequences picked at random from the training-data.\n",
    "\n",
    "def batch_generator(batch_size, sequence_length):\n",
    "    \"\"\"\n",
    "    Generator function for creating random batches of training-data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Infinite loop.\n",
    "    while True:\n",
    "        # Allocate a new array for the batch of input-signals.\n",
    "        x_shape = (batch_size, sequence_length, num_x_signals)\n",
    "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
    "\n",
    "        # Allocate a new array for the batch of output-signals.\n",
    "        y_shape = (batch_size, sequence_length, num_y_signals)\n",
    "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
    "\n",
    "        # Fill the batch with random sequences of data.\n",
    "        for i in range(batch_size):\n",
    "            # Get a random start-index.\n",
    "            # This points somewhere into the training-data.\n",
    "            idx = np.random.randint(num_train - sequence_length)\n",
    "            \n",
    "            # Copy the sequences of data starting at this index.\n",
    "            x_batch[i] = x_train_scaled[idx:idx+sequence_length]\n",
    "            y_batch[i] = y_train_scaled[idx:idx+sequence_length]\n",
    "        \n",
    "        yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#batch_size = 256\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sequence_length = 450\n",
    "sequence_length = 75\n",
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We then create the batch-generator.\n",
    "generator = batch_generator(batch_size=batch_size, sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We can then test the batch-generator to see if it works.\n",
    "x_batch, y_batch = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 75, 16)\n",
      "(50, 75, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_batch.shape)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Validation Set:\n",
    "\n",
    "The neural network trains quickly so we can easily run many training epochs. But then there is a risk of overfitting the \n",
    "model to the training-set so it does not generalize well to unseen data. We will therefore monitor the model's performance \n",
    "on the test-set after each epoch and only save the model's weights if the performance is improved on the test-set.\n",
    "\n",
    "The batch-generator randomly selects a batch of short sequences from the training-data and uses that during training. But for\n",
    "the validation-data we will instead run through the entire sequence from the test-set and measure the prediction accuracy on \n",
    "that entire sequence.\n",
    "\"\"\"\n",
    "\n",
    "validation_data = (np.expand_dims(x_test_scaled, axis=0), np.expand_dims(y_test_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the Recurrent Neural Network:\n",
    "\n",
    "We are now ready to create the Recurrent Neural Network (RNN). We will use the Keras API for this because of its simplicity. \n",
    "\"\"\"\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can now add a Gated Recurrent Unit (GRU) to the network. This will have 512 outputs for each time-step in the sequence.\n",
    "\n",
    "Note that because this is the first layer in the model, Keras needs to know the shape of its input, which is a batch of \n",
    "sequences of arbitrary length (indicated by None), where each observation has a number of input-signals (num_x_signals).\n",
    "\"\"\"\n",
    "\n",
    "model.add(GRU(units=512, return_sequences=True, input_shape=(None, num_x_signals,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_y_signals, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from tensorflow.python.keras.initializers import RandomUniform\n",
    "\n",
    "    # Maybe use lower init-ranges.\n",
    "    init = RandomUniform(minval=-0.05, maxval=0.05)\n",
    "\n",
    "    model.add(Dense(num_y_signals,activation='linear',kernel_initializer=init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warmup_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_mse_warmup(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error between y_true and y_pred,\n",
    "    but ignore the beginning \"warmup\" part of the sequences.\n",
    "    \n",
    "    y_true is the desired output.\n",
    "    y_pred is the model's output.\n",
    "    \"\"\"\n",
    "\n",
    "    # The shape of both input tensors are:\n",
    "    # [batch_size, sequence_length, num_y_signals].\n",
    "\n",
    "    # Ignore the \"warmup\" parts of the sequences\n",
    "    # by taking slices of the tensors.\n",
    "    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "\n",
    "    # These sliced tensors both have this shape:\n",
    "    # [batch_size, sequence_length - warmup_steps, num_y_signals]\n",
    "\n",
    "    # Calculate the MSE loss for each value in these tensors.\n",
    "    # This outputs a 3-rank tensor of the same shape.\n",
    "    loss = tf.losses.mean_squared_error(labels=y_true_slice,\n",
    "                                        predictions=y_pred_slice)\n",
    "\n",
    "    # Keras may reduce this across the first axis (the batch)\n",
    "    # but the semantics are unclear, so to be sure we use\n",
    "    # the loss across the entire tensor, we reduce it to a\n",
    "    # single scalar with the mean function.\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We then compile the Keras model so it is ready for training.\n",
    "model.compile(loss=loss_mse_warmup, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, None, 512)         812544    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 2)           1026      \n",
      "=================================================================\n",
      "Total params: 813,570\n",
      "Trainable params: 813,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_checkpoint = '23_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the callback for stopping the optimization when performance worsens on the validation-set.\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the callback for writing the TensorBoard log during training.\n",
    "callback_tensorboard = TensorBoard(log_dir='./23_logs/',histogram_freq=0, write_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-4,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint,\n",
    "             callback_tensorboard,\n",
    "             callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.2213Epoch 00000: val_loss improved from inf to 0.18733, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 59s - loss: 0.2202 - val_loss: 0.1873\n",
      "Epoch 2/15\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1765Epoch 00001: val_loss improved from 0.18733 to 0.17114, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 53s - loss: 0.1761 - val_loss: 0.1711\n",
      "Epoch 3/15\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1664Epoch 00002: val_loss improved from 0.17114 to 0.15720, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 53s - loss: 0.1661 - val_loss: 0.1572\n",
      "Epoch 4/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1592Epoch 00003: val_loss did not improve\n",
      "\n",
      "Epoch 00003: reducing learning rate to 0.00010000000474974513.\n",
      "25/25 [==============================] - 55s - loss: 0.1592 - val_loss: 0.1583\n",
      "Epoch 5/15\n",
      "24/25 [===========================>..] - ETA: 1s - loss: 0.1513Epoch 00004: val_loss improved from 0.15720 to 0.14764, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 54s - loss: 0.1511 - val_loss: 0.1476\n",
      "Epoch 6/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1473Epoch 00005: val_loss improved from 0.14764 to 0.14659, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 56s - loss: 0.1475 - val_loss: 0.1466\n",
      "Epoch 7/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1464Epoch 00006: val_loss improved from 0.14659 to 0.14622, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 57s - loss: 0.1464 - val_loss: 0.1462\n",
      "Epoch 8/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1461Epoch 00007: val_loss improved from 0.14622 to 0.14539, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 58s - loss: 0.1460 - val_loss: 0.1454\n",
      "Epoch 9/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1457Epoch 00008: val_loss improved from 0.14539 to 0.14384, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 58s - loss: 0.1458 - val_loss: 0.1438\n",
      "Epoch 10/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1470Epoch 00009: val_loss improved from 0.14384 to 0.14309, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 57s - loss: 0.1470 - val_loss: 0.1431\n",
      "Epoch 11/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1431Epoch 00010: val_loss improved from 0.14309 to 0.14232, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 59s - loss: 0.1432 - val_loss: 0.1423\n",
      "Epoch 12/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1426Epoch 00011: val_loss improved from 0.14232 to 0.14199, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 60s - loss: 0.1428 - val_loss: 0.1420\n",
      "Epoch 13/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1439Epoch 00012: val_loss improved from 0.14199 to 0.14134, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 58s - loss: 0.1439 - val_loss: 0.1413\n",
      "Epoch 14/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1428Epoch 00013: val_loss improved from 0.14134 to 0.14049, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 60s - loss: 0.1428 - val_loss: 0.1405\n",
      "Epoch 15/15\n",
      "24/25 [===========================>..] - ETA: 2s - loss: 0.1400Epoch 00014: val_loss improved from 0.14049 to 0.13884, saving model to 23_checkpoint.keras\n",
      "25/25 [==============================] - 59s - loss: 0.1403 - val_loss: 0.1388\n",
      "Wall time: 14min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1d05616b6a0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(generator=generator,\n",
    "                    #epochs=20,\n",
    "                    epochs=15,\n",
    "                    #steps_per_epoch=100,\n",
    "                    steps_per_epoch=25,\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s\n",
      "0.138835772872\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Performance on Test-Set:\n",
    "\n",
    "We can now evaluate the model's performance on the test-set. This function expects a batch of data, but we will just use one \n",
    "long time-series for the test-set, so we just expand the array-dimensionality to create a batch with that one sequence.\n",
    "\"\"\"\n",
    "result = model.evaluate(x=np.expand_dims(x_test_scaled, axis=0),\n",
    "                        y=np.expand_dims(y_test_scaled, axis=0))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss (test-set): 0.138835772872\n"
     ]
    }
   ],
   "source": [
    "print(\"loss (test-set):\", result)\n",
    "# If you have several metrics you can use this instead.\n",
    "if False:\n",
    "    for res, metric in zip(result, model.metrics_names):\n",
    "        print(\"{0}: {1:.3e}\".format(metric, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_comparison(start_idx, length=100, train=True):\n",
    "    \"\"\"\n",
    "    Plot the predicted and true output-signals.\n",
    "    \n",
    "    :param start_idx: Start-index for the time-series.\n",
    "    :param length: Sequence-length to process and plot.\n",
    "    :param train: Boolean whether to use training- or test-set.\n",
    "    \"\"\"\n",
    "    \n",
    "    if train:\n",
    "        # Use training-data.\n",
    "        x = x_train_scaled\n",
    "        y_true = y_train\n",
    "    else:\n",
    "        # Use test-data.\n",
    "        x = x_test_scaled\n",
    "        y_true = y_test\n",
    "    \n",
    "    # End-index for the sequences.\n",
    "    end_idx = start_idx + length\n",
    "    \n",
    "    # Select the sequences from the given start-index and\n",
    "    # of the given length.\n",
    "    x = x[start_idx:end_idx]\n",
    "    y_true = y_true[start_idx:end_idx]\n",
    "    \n",
    "    # Input-signals for the model.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Use the model to predict the output-signals.\n",
    "    y_pred = model.predict(x)\n",
    "    # The output of the model is between 0 and 1.\n",
    "    # Do an inverse map to get it back to the scale\n",
    "    # of the original data-set.\n",
    "    y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])  \n",
    "    print('Previsoes:', y_pred_rescaled)\n",
    "    print('Real:', y_true)  \n",
    "    \n",
    "    \"\"\"\n",
    "    # For each output-signal.\n",
    "    for signal in range(len(target_name)):\n",
    "        # Get the output-signal predicted by the model.\n",
    "        signal_pred = y_pred_rescaled[:, signal]\n",
    "        \n",
    "        # Get the true output-signal from the data-set.\n",
    "        signal_true = y_true[:, signal]\n",
    "\n",
    "        # Make the plotting-canvas bigger.\n",
    "        plt.figure(figsize=(15,5))\n",
    "        \n",
    "        # Plot and compare the two signals.\n",
    "        plt.plot(signal_true, label='true')\n",
    "        plt.plot(signal_pred, label='pred')\n",
    "        \n",
    "        # Plot grey box for warmup-period.\n",
    "        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n",
    "        \n",
    "        # Plot labels etc.\n",
    "        plt.ylabel(target_name[signal])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "     \"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsoes: [[ 0.52386218  0.51255918]\n",
      " [ 0.98990029  0.98945528]\n",
      " [ 0.98816073  0.98848104]\n",
      " [ 0.68588912  0.69752252]\n",
      " [ 0.39837825  0.4113231 ]\n",
      " [ 0.61949348  0.62437916]\n",
      " [ 0.15522966  0.1557842 ]\n",
      " [ 0.10198675  0.10242577]\n",
      " [ 0.24104708  0.24018288]\n",
      " [ 0.9428677   0.94364852]]\n",
      "Real: [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "plot_comparison(start_idx=8810, length=10, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor Binário (0) ADS.DE --> [[ 0.7  0.7]\n",
      " [ 1.   1. ]\n",
      " [ 1.   1. ]\n",
      " [ 0.5  0.5]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) ALV.DE --> [[ 1.   1. ]\n",
      " [ 1.   1. ]\n",
      " [ 0.9  0.9]\n",
      " [ 0.2  0.2]\n",
      " [ 0.2  0.2]]\n",
      "Valor Binário (0) BAS.DE --> [[ 1.   1. ]\n",
      " [ 0.9  0.9]\n",
      " [ 1.   1. ]\n",
      " [ 0.8  0.8]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) BAYN.DE --> [[ 0.6  0.6]\n",
      " [ 0.1  0.1]\n",
      " [ 0.6  0.6]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) BEI.DE --> [[ 0.   0. ]\n",
      " [ 0.9  0.9]\n",
      " [ 0.9  0.9]\n",
      " [ 0.7  0.7]\n",
      " [ 0.4  0.4]]\n",
      "Valor Binário (0) BMW.DE --> [[ 1.   1. ]\n",
      " [ 0.9  0.9]\n",
      " [ 0.2  0.2]\n",
      " [ 0.1  0.1]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) CBK.DE --> [[ 1.   1. ]\n",
      " [ 0.7  0.6]\n",
      " [ 0.1  0.1]\n",
      " [ 0.1  0.1]\n",
      " [ 0.2  0.2]]\n",
      "Valor Binário (0) CON.DE --> [[ 1.   1. ]\n",
      " [ 0.9  0.9]\n",
      " [ 0.3  0.3]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) DAI.DE --> [[ 1.   1. ]\n",
      " [ 1.   1. ]\n",
      " [ 0.8  0.8]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) DB1.DE --> [[ 0.9  0.9]\n",
      " [ 0.9  0.9]\n",
      " [ 0.9  0.9]\n",
      " [ 0.7  0.7]\n",
      " [ 0.2  0.1]]\n",
      "Valor Binário (0) DBK.DE --> [[ 1.   1. ]\n",
      " [ 0.5  0.5]\n",
      " [ 0.1  0.1]\n",
      " [ 0.2  0.2]\n",
      " [ 0.9  0.9]]\n",
      "Valor Binário (0) DPW.DE --> [[ 1.   0.9]\n",
      " [ 1.   1. ]\n",
      " [ 0.8  0.8]\n",
      " [ 0.8  0.8]\n",
      " [ 0.4  0.3]]\n",
      "Valor Binário (0) DTE.DE --> [[ 0.4  0.4]\n",
      " [ 0.9  0.9]\n",
      " [ 1.   1. ]\n",
      " [ 0.3  0.3]\n",
      " [ 0.1  0.1]]\n",
      "Valor Binário (0) EOAN.DE --> [[ 0.   0. ]\n",
      " [ 0.9  0.9]\n",
      " [ 0.9  0.9]\n",
      " [ 0.2  0.2]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) FME.DE --> [[ 0.1  0.1]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.8  0.8]\n",
      " [ 0.6  0.6]]\n",
      "Valor Binário (0) FRE.DE --> [[ 0.   0. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.8  0.7]\n",
      " [ 0.9  0.9]\n",
      " [ 0.3  0.3]]\n",
      "Valor Binário (0) HEI.DE --> [[ 0.9  0.9]\n",
      " [ 1.   1. ]\n",
      " [ 0.8  0.8]\n",
      " [ 0.5  0.5]\n",
      " [ 0.1  0.1]]\n",
      "Valor Binário (0) HEN3.DE --> [[ 0.8  0.7]\n",
      " [ 0.8  0.8]\n",
      " [ 0.1  0.1]\n",
      " [ 0.6  0.6]\n",
      " [ 0.8  0.8]]\n",
      "Valor Binário (0) IFX.DE --> [[ 1.   1. ]\n",
      " [ 0.9  0.8]\n",
      " [ 0.7  0.7]\n",
      " [ 0.7  0.7]\n",
      " [ 0.7  0.7]]\n",
      "Valor Binário (0) LHA.DE --> [[ 0.6  0.6]\n",
      " [ 0.9  0.9]\n",
      " [ 0.5  0.5]\n",
      " [ 0.1  0.1]\n",
      " [ 0.3  0.3]]\n",
      "Valor Binário (0) LIN.DE --> [[ 0.1  0.1]\n",
      " [ 0.9  0.9]\n",
      " [ 0.2  0.1]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) MRK.DE --> [[ 0.2  0.2]\n",
      " [ 0.1  0.1]\n",
      " [ 0.7  0.7]\n",
      " [ 0.9  0.9]\n",
      " [ 0.7  0.7]]\n",
      "Valor Binário (0) MUV2.DE --> [[ 0.9  0.9]\n",
      " [ 0.9  0.9]\n",
      " [ 0.9  0.8]\n",
      " [ 0.5  0.4]\n",
      " [ 0.5  0.4]]\n",
      "Valor Binário (0) PSM.DE --> [[ 0.7  0.7]\n",
      " [ 0.9  0.9]\n",
      " [ 0.9  0.9]\n",
      " [ 0.2  0.2]\n",
      " [ 0.   0. ]]\n",
      "Valor Binário (0) RWE.DE --> [[ 0.1  0. ]\n",
      " [ 0.2  0.2]\n",
      " [ 0.3  0.2]\n",
      " [ 0.3  0.3]\n",
      " [ 0.2  0.2]]\n",
      "Valor Binário (0) SAP.DE --> [[ 0.1  0.1]\n",
      " [ 0.8  0.8]\n",
      " [ 1.   1. ]\n",
      " [ 1.   1. ]\n",
      " [ 0.9  0.9]]\n",
      "Valor Binário (0) SIE.DE --> [[ 0.9  0.9]\n",
      " [ 0.9  0.9]\n",
      " [ 0.4  0.3]\n",
      " [ 0.2  0.2]\n",
      " [ 0.6  0.5]]\n",
      "Valor Binário (0) TKA.DE --> [[ 1.   1. ]\n",
      " [ 0.9  0.9]\n",
      " [ 0.1  0.1]\n",
      " [ 0.   0. ]\n",
      " [ 0.3  0.3]]\n",
      "Valor Binário (0) VNA.DE --> [[ 0.1  0.1]\n",
      " [ 0.9  0.9]\n",
      " [ 1.   1. ]\n",
      " [ 1.   1. ]\n",
      " [ 1.   1. ]]\n",
      "Valor Binário (0) VOW3.DE --> [[ 1.   1. ]\n",
      " [ 1.   1. ]\n",
      " [ 0.1  0.1]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from stockstats import StockDataFrame as Sdf\n",
    "from ta import *\n",
    "%matplotlib inline\n",
    "\n",
    "nome_ficheiro = 'lista_dax.txt'\n",
    "#nome_ficheiro = 'lista_dowj.csv'\n",
    "\n",
    "try:\n",
    "        fhand = open(nome_ficheiro)\n",
    "\n",
    "except:\n",
    "        print ('Nao e possivel abrir o ficheiro: ', fhand)\n",
    "\n",
    "\n",
    "lista_quotes = []\n",
    "\n",
    "#Cria lista com os ticket do SP500\n",
    "for f in fhand:\n",
    "    linha = f.strip().split(',')\n",
    "    ticker = linha[0]\n",
    "    lista_quotes.append(ticker)\n",
    "\n",
    "\n",
    "for quote in lista_quotes:\n",
    "    try:\n",
    "        stock = pd.read_csv('dados_actuais_'+quote+'_280419.csv')\n",
    "        #stock = pd.read_csv('dados_actuais_dowj_'+quote+'_260419.csv')\n",
    "        output = stock\n",
    "    except:\n",
    "        continue    \n",
    "    \n",
    "    # Utilizando a livaria 'ta'\n",
    "    # Add bollinger band high indicator filling NaN values\n",
    "    output['bb_high_indicator'] = bollinger_hband_indicator(output[\"Close\"], n=20, ndev=2, fillna=True)\n",
    "    # Add bollinger band low indicator filling NaN values\n",
    "    output['bb_low_indicator'] = bollinger_lband_indicator(output[\"Close\"], n=20, ndev=2, fillna=True)\n",
    "    # Adicionar Money Flow Index\n",
    "    output['MoneyFlowIndex'] = money_flow_index(output[\"High\"],output[\"Low\"],output[\"Close\"],output[\"Volume\"],n=14, fillna=True)\n",
    "    # Adicionar AwesomeOscillator\n",
    "    output['AwesomeOscillator'] = ao(output[\"High\"],output[\"Low\"], s=5, l=34, fillna=True)\n",
    "    # Adicionar Stochatic Oscillator\n",
    "    output['StochaticOscillator'] = stoch(output[\"High\"],output[\"Low\"],output[\"Close\"], n=14, fillna=True)\n",
    "    # Adicionar Stochatic Oscillator Signal\n",
    "    output['StochaticOscillatorSignal'] = stoch_signal(output[\"High\"],output[\"Low\"],output[\"Close\"], n=14, d_n=3, fillna=True)\n",
    "    # Adicionar True Strength Index\n",
    "    output['TrueStrengthIndex'] = tsi(output[\"Close\"], r=25, s=13, fillna=True)\n",
    "    # Adicionar Ultimate Oscillator\n",
    "    output['UltimateOscillator'] = uo(output[\"High\"],output[\"Low\"],output[\"Close\"], s=7, m=14, l=28, ws=4.0, wm=2.0, wl=1.0, fillna=True)\n",
    "    # Adicionar William % R\n",
    "    output['William%R'] = wr(output[\"High\"],output[\"Low\"],output[\"Close\"], lbp=14, fillna=True)\n",
    "    # Adicionar RSI\n",
    "    output['RSI'] = rsi(output[\"Close\"], n=14, fillna=True)\n",
    "    \n",
    "    # Adicionar features (MM4,MM9,MM18) e uma label (1=Subiu, 0=Desceu)\n",
    "\n",
    "    output['Change'] = output['Close'].pct_change()\n",
    "    output['UP'] = np.where(output['Change'] >= 0.0,1,0)\n",
    "    output['MM4'] = output['Close'].rolling(window=4).mean()\n",
    "    output['MM9'] = output['Close'].rolling(window=9).mean()\n",
    "    output['MM18'] = output['Close'].rolling(window=18).mean()\n",
    "    output['CrossMM'] = np.where(output['MM4'] > output['MM18'],1.0,0.0)\n",
    "    output['CrossPrice'] = np.where(output['Open'] > output['MM18'],1.0,0.0)\n",
    "    \n",
    "    # Preencher os dados em falta\n",
    "\n",
    "    media4 = output['MM4'].mean()\n",
    "    media9 = output['MM9'].mean()\n",
    "    media18 = output['MM18'].mean()\n",
    "    output['MM4'].fillna(media4, inplace=True)\n",
    "    output['MM9'].fillna(media9, inplace=True)\n",
    "    output['MM18'].fillna(media18, inplace=True)\n",
    "    output['Change'].fillna(0, inplace=True)    \n",
    "    \n",
    "    \n",
    "    # Criar tabela com 'features', e com respectiva label (UP)\n",
    "    y = output['UP']\n",
    "    X = output[['Volume','High','Low','RSI','CrossMM','CrossPrice','bb_high_indicator','MoneyFlowIndex','Open','MM4','MM9','MM18','StochaticOscillator', 'William%R', 'UltimateOscillator', 'StochaticOscillatorSignal' ]]\n",
    "\n",
    "    #Split \n",
    "    \n",
    "    tamanho_t = len(X)\n",
    "    terco = int(tamanho_t/3)\n",
    "    tr = tamanho_t - terco\n",
    "    \n",
    "    \n",
    "    x_train = X.head(tr)\n",
    "    x_test  = X.tail(terco)\n",
    "    y_train = y.head(tr)\n",
    "    y_test = y.tail(terco)\n",
    "    \n",
    "    \n",
    "    x_scaler = MinMaxScaler()\n",
    "    x_train_scaled = x_scaler.fit_transform(x_train)\n",
    "    x_test_scaled = x_scaler.transform(x_test)\n",
    "    \n",
    "          \n",
    "    \n",
    "    \"\"\"\n",
    "    #Scaling\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train_sca = sc.fit_transform(X_train)\n",
    "    X_test_sca = sc.transform(X_test)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def comparison(start_idx, length=100, train=True):\n",
    "        \"\"\"\n",
    "        Plot the predicted and true output-signals.\n",
    "\n",
    "        :param start_idx: Start-index for the time-series.\n",
    "        :param length: Sequence-length to process and plot.\n",
    "        :param train: Boolean whether to use training- or test-set.\n",
    "        \"\"\"\n",
    "\n",
    "        if train:\n",
    "            # Use training-data.\n",
    "            x = x_train_scaled\n",
    "            y_true = y_train\n",
    "        else:\n",
    "            # Use test-data.\n",
    "            x = x_test_scaled\n",
    "            y_true = y_test\n",
    "\n",
    "        # End-index for the sequences.\n",
    "        end_idx = start_idx + length\n",
    "\n",
    "        # Select the sequences from the given start-index and\n",
    "        # of the given length.\n",
    "        x = x[start_idx:end_idx]\n",
    "        y_true = y_true[start_idx:end_idx]\n",
    "\n",
    "        # Input-signals for the model.\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        # Use the model to predict the output-signals.\n",
    "        y_pred = model.predict(x)\n",
    "        # The output of the model is between 0 and 1.\n",
    "        # Do an inverse map to get it back to the scale\n",
    "        # of the original data-set.\n",
    "        y_pred_rescaled = y_scaler.inverse_transform(y_pred[0])  \n",
    "        return y_pred_rescaled      \n",
    "    \n",
    "    \n",
    "    \n",
    "    x_pred_rescaled = comparison(start_idx=1, length=500, train=False)\n",
    "    \n",
    "    \n",
    "    #y_pred = model.predict(x)    \n",
    "    #y_pred = model.predict(x_test_sca).astype(np.double).round(decimals=1)[-5:]\n",
    "    print('Valor Binário (0)', quote, '-->', x_pred_rescaled.astype(np.double).round(decimals=1)[-5:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
